{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Imports and Constants"
      ],
      "metadata": {
        "id": "_JXCcSApbhes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# List of ICPAC countries\n",
        "icpac_countries = [\n",
        "    \"Kenya\", \"Somalia\", \"Ethiopia\", \"South Sudan\", \"Uganda\", \"Tanzania\", \"Rwanda\", \"Burundi\", 'Sudan', 'Djibouti', 'Eritrea'\n",
        "]\n",
        "\n",
        "# Base URL for GLIDE search\n",
        "search_url = \"https://www.glidenumber.net/glide/public/search/search.jsp\"\n",
        "report_url = \"https://www.glidenumber.net/glide/public/result/report.jsp\"\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
      ],
      "metadata": {
        "id": "MvvnuMaWC8C1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function Definition"
      ],
      "metadata": {
        "id": "TpQ6vJJQbkPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform search and extract data\n",
        "def perform_search_and_extract():\n",
        "    data = []\n",
        "    page = 1\n",
        "\n",
        "    while True:\n",
        "        search_payload = {\n",
        "            'continent': 'Africa',\n",
        "            'country': 'icpac_countries',\n",
        "            'event': 'Any',\n",
        "            'hits_per_page': 25,\n",
        "            'sort_order': 'desc',\n",
        "            'page': page\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Perform the search\n",
        "            search_response = requests.post(search_url, data=search_payload)\n",
        "            search_response.raise_for_status()  # Check for request errors\n",
        "        except requests.RequestException as e:\n",
        "            logging.error(f\"Search failed with exception: {e}\")\n",
        "            break\n",
        "\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(search_response.content, 'html.parser')\n",
        "\n",
        "        # Extract table rows from the search results\n",
        "        rows = soup.find_all('tr')[1:]  # Skip header row\n",
        "        if not rows:\n",
        "            logging.info(f\"No more data found on page {page}. Ending extraction.\")\n",
        "            break  # Exit loop if no rows are found (end of pages)\n",
        "\n",
        "        for row in rows:\n",
        "            cols = row.find_all('td')\n",
        "            if len(cols) >= 11:  # Ensure there are enough columns\n",
        "                record = {\n",
        "                    'GLIDE Number': cols[0].text.strip(),\n",
        "                    'Event': cols[1].text.strip(),\n",
        "                    'Country': cols[2].text.strip(),\n",
        "                    'Date': cols[3].text.strip() if len(cols) > 3 else \"\",\n",
        "                    'Event Code': cols[4].text.strip() if len(cols) > 4 else \"\",\n",
        "                    'GLIDE Serial': cols[5].text.strip() if len(cols) > 5 else \"\",\n",
        "                    'Country Code': cols[6].text.strip() if len(cols) > 6 else \"\",\n",
        "                    'Year': cols[7].text.strip() if len(cols) > 7 else \"\",\n",
        "                    'Month': cols[8].text.strip() if len(cols) > 8 else \"\",\n",
        "                    'Day': cols[9].text.strip() if len(cols) > 9 else \"\",\n",
        "                    'Time': cols[10].text.strip() if len(cols) > 10 else \"\",\n",
        "                    'Location': cols[11].text.strip() if len(cols) > 11 else \"\",\n",
        "                    'Duration': cols[12].text.strip() if len(cols) > 12 else \"\",\n",
        "                    'Magnitude': cols[13].text.strip() if len(cols) > 13 else \"\",\n",
        "                    'Info Source': cols[14].text.strip() if len(cols) > 14 else \"\",\n",
        "                    'Comments': cols[15].text.strip() if len(cols) > 15 else \"\",\n",
        "                    'Latitude': cols[16].text.strip() if len(cols) > 16 else \"\",\n",
        "                    'Longitude': cols[17].text.strip() if len(cols) > 17 else \"\",\n",
        "                    'Date Created': cols[20].text.strip() if len(cols) > 20 else \"\",\n",
        "                    'Updated': cols[21].text.strip() if len(cols) > 21 else \"\"\n",
        "                }\n",
        "\n",
        "                if record['Country'] in icpac_countries:\n",
        "                    data.append(record)\n",
        "\n",
        "        logging.info(f\"Page {page} processed with {len(rows)} records.\")\n",
        "        page += 1  # Move to the next page\n",
        "        time.sleep(1)\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "wRFxq6gjMTdX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Extraction"
      ],
      "metadata": {
        "id": "O0L-NL0sbpci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "icpac_data = await perform_search_and_extract()"
      ],
      "metadata": {
        "id": "yxoz4gJPbsFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Handling and Output"
      ],
      "metadata": {
        "id": "kn5hjM0ybt5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame and save to CSV\n",
        "df = pd.DataFrame(icpac_data)\n",
        "df.to_csv('icpac_disaster_data.csv', index=False)\n",
        "logging.info(\"Data extraction completed and saved to icpac_disaster_data.csv\")"
      ],
      "metadata": {
        "id": "o8ah61ofbwbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('icpac_disaster_data.csv')\n"
      ],
      "metadata": {
        "id": "CqZqLnp1tJoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LETVySJEEBC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D6E3GLicECB3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}