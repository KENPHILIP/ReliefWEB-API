# -*- coding: utf-8 -*-
"""HDX_DATA_EXTRACT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hxhIiJfq1MX4rPhVD4R944Xhex0KHQs2

# ICPAC Countries Data Fetching Script (HDX)

## Overview

This script is designed to download CSV files related to specific ICPAC countries from the Humanitarian Data Exchange (HDX) and organize them into separate folders for each country. The ICPAC countries included are Djibouti, Eritrea, Ethiopia, Kenya, Somalia, South Sudan, Sudan, Uganda, Burundi, Rwanda, and Tanzania.

## Script Enhancements

The script has been enhanced with several features to ensure robust data fetching and organization:

1. **Enhanced Logging**: The script now includes print statements that log the process of fetching data for each country. This helps in tracking which country's data is being processed and whether datasets are found.

2. **Error Handling**: Added `try-except` blocks around the `requests.get` calls to handle potential HTTP errors and other exceptions. This ensures that the script can handle issues gracefully and provides meaningful error messages.

3. **Modified Search Parameters**: Adjusted the search parameters to include a simple query for the country name (`q`) and a filter for CSV resources (`fq`). This change aims to improve the relevance of the search results.

4. **Directory Structure**: For each ICPAC country, a directory is created to store the corresponding CSV files. This organization helps in maintaining a clear structure for the downloaded data.

5. **Download Function**: The function `download_file` is used to handle the downloading of files. It checks the response status and writes the content to a file in chunks to handle large files efficiently.

## Usage

 The script automatically create a directory named `hdx_csv_files` with subdirectories for each ICPAC country, where the downloaded CSV files will be stored.
"""

import requests
import os

# HDX endpoint url
hdx_url = "https://data.humdata.org/api/3/action/package_search"
icpac_countries = [
    "Djibouti", "Eritrea", "Ethiopia", "Kenya", "Somalia", "South Sudan",
    "Sudan", "Uganda", "Burundi", "Rwanda", "Tanzania"
]

# Function to download a file from a URL
def download_file(url, save_path):
    try:
        response = requests.get(url, stream=True)
        if response.status_code == 200:
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024):
                    f.write(chunk)
            print(f"Downloaded: {save_path}")
        else:
            print(f"Failed to download {url}: {response.status_code}")
    except Exception as e:
        print(f"Error downloading {url}: {str(e)}")

# Loop through each ICPAC country and retrieve data
for country in icpac_countries:
    print(f"Fetching data for {country}...")
    params = {
        "q": country,
        "fq": "res_format:CSV",
        "sort": "metadata_modified desc",
        "rows": 25
    }

    # Create a directory for each country to save the CSV files
    country_dir = os.path.join("hdx_csv_files", country)
    os.makedirs(country_dir, exist_ok=True)

    # Fetch datasets from HDX
    try:
        response = requests.get(hdx_url, params=params)
        response.raise_for_status()  # Raises an HTTPError for bad responses
        datasets = response.json().get('result', {}).get('results', [])
        if not datasets:
            print(f"No datasets found for {country}")
        for dataset in datasets:
            resources = dataset.get('resources', [])
            for resource in resources:
                if resource.get('format', '').lower() == 'csv':
                    file_url = resource.get('url')
                    file_name = resource.get('name', 'downloaded_file.csv').replace('/', '_')
                    save_path = os.path.join(country_dir, file_name)
                    download_file(file_url, save_path)
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP error occurred for {country}: {http_err}")
    except Exception as err:
        print(f"An error occurred for {country}: {err}")

print("All CSV files have been processed and organized by country.")

import zipfile
import shutil

# Function to zip files in a directory
def zip_directory(directory_path, zip_path):
    try:
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(directory_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    zipf.write(file_path, os.path.relpath(file_path, directory_path))
        print(f"Zipped: {zip_path}")
    except Exception as e:
        print(f"Error zipping directory {directory_path}: {str(e)}")

# Create a parent directory for all zipped files
zipped_dir = "hdx_zipped_files"
os.makedirs(zipped_dir, exist_ok=True)

# Loop through each country directory and zip the contents
for country in icpac_countries:
    country_dir = os.path.join("hdx_csv_files", country)
    if os.path.exists(country_dir) and os.listdir(country_dir):  # Check if directory exists and is not empty
        zip_path = os.path.join(zipped_dir, f"{country}.zip")
        zip_directory(country_dir, zip_path)
    else:
        print(f"No files to zip for {country}")

print("All directories have been zipped and organized.")

